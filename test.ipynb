{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ebd59db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: BNB_CUDA_VERSION=122 environment variable detected; loading libbitsandbytes_cuda122.so.\n",
      "This can be used to load a bitsandbytes version that is different from the PyTorch CUDA version.\n",
      "If this was unintended set the BNB_CUDA_VERSION variable to an empty string: export BNB_CUDA_VERSION=\n",
      "If you use the manual override make sure the right libcudart.so is in your LD_LIBRARY_PATH\n",
      "For example by adding the following to your .bashrc: export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:<path_to_cuda_dir/lib64\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alpaco/anaconda3/envs/fast_chat/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2025.5.7: Fast Mistral patching. Transformers: 4.51.3.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 3090. Num GPUs = 1. Max memory: 23.691 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.4.0+cu121. CUDA: 8.6. CUDA Toolkit: 12.1. Triton: 3.0.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.27.post2+cu118. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "# Unsloth ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ FastLanguageModelì„ ì„í¬íŠ¸\n",
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "\n",
    "max_seq_length = 2048 # ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´ë¥¼ ì„¤ì • ( í…ìŠ¤íŠ¸ì˜ ìµœëŒ€ ê¸¸ì´ë¥¼ ì§€ì •)\n",
    "dtype = None  # ìë™ ê°ì§€ë¥¼ ìœ„í•´ None ì„¤ì •. Tesla T4ëŠ” Float16, Ampere+ëŠ” Bfloat16 ì‚¬ìš©. ëª¨ë¸ì˜ íŒŒë¼ë¯¸í„°ë¥¼ ì €ì¥í•  ë°ì´í„° íƒ€ì…\n",
    "load_in_4bit = True  # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ì¤„ì´ê¸° ìœ„í•´ 4ë¹„íŠ¸ ì–‘ìí™” ì‚¬ìš©. ë‹¤ë§Œ ì–‘ìí™”ì— ë”°ë¥¸ ì†ì‹¤ì´ ìˆì–´ì„œ í•„ìš”ì— ë”°ë¼ Falseë¡œ ì„¤ì • ê°€ëŠ¥\n",
    "\n",
    "# ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¡œë“œ\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",  # ì‚¬ìš©í•  ëª¨ë¸ ì´ë¦„\n",
    "    max_seq_length = max_seq_length,         # ì„¤ì •í•œ ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´\n",
    "    dtype = dtype,                           # ë°ì´í„° íƒ€ì… ì„¤ì •\n",
    "    load_in_4bit = load_in_4bit,             # 4ë¹„íŠ¸ ì–‘ìí™” ì—¬ë¶€\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "247add3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.5.7 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "# PEFT(íŒŒë¼ë¯¸í„° íš¨ìœ¨ì  íŒŒì¸íŠœë‹) ëª¨ë¸ ì„¤ì •\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16,  # LoRA ë­í¬ ì„¤ì •. 8, 16, 32, 64, 128 ê¶Œì¥. r ê°’ì´ í´ìˆ˜ë¡ ëª¨ë¸ì´ ë” ë§ì€ ì •ë³´ë¥¼ í•™ìŠµí•  ìˆ˜ ìˆì§€ë§Œ, ë„ˆë¬´ í¬ë©´ ë©”ëª¨ë¦¬ë¥¼ ë§ì´ ì‚¬ìš©\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\"],  # PEFT ì ìš©í•  ëª¨ë“ˆ ëª©ë¡. ëª¨ë¸ì˜ íŠ¹ì • ë¶€ë¶„(ëª¨ë“ˆ)ì—ë§Œ í•™ìŠµ\n",
    "    lora_alpha = 16,        # LoRA ì•ŒíŒŒ ì„¤ì • LoRAë¼ëŠ” ê¸°ìˆ ì´ ì–¼ë§ˆë‚˜ ê°•í•˜ê²Œ ì‘ìš©í• ì§€ ì¡°ì ˆ\n",
    "    lora_dropout = 0,       # LoRA ë“œë¡­ì•„ì›ƒ ì„¤ì •. 0ìœ¼ë¡œ ìµœì í™”\n",
    "    bias = \"none\",          # ë°”ì´ì–´ìŠ¤ ì„¤ì •. \"none\"ìœ¼ë¡œ ìµœì í™”\n",
    "\n",
    "    # \"unsloth\" ì‚¬ìš© ì‹œ VRAM ì ˆì•½ ë° ë°°ì¹˜ ì‚¬ì´ì¦ˆ 2ë°° ì¦ê°€\n",
    "    # í•™ìŠµí•  ë•Œ ë©”ëª¨ë¦¬ë¥¼ ì ˆì•½í•˜ëŠ” ë°©ë²•ì„ ì‚¬ìš©í•˜ëŠ” ì„¤ì •\n",
    "    use_gradient_checkpointing = \"unsloth\",  # ë§¤ìš° ê¸´ ì»¨í…ìŠ¤íŠ¸ë¥¼ ìœ„í•´ \"unsloth\" ì„¤ì •\n",
    "    random_state = 3407,    # ëœë¤ ì‹œë“œ ì„¤ì •\n",
    "    use_rslora = False,     # ë­í¬ ì•ˆì •í™” LoRA ì‚¬ìš© ì—¬ë¶€\n",
    "    loftq_config = None,    # LoftQ ì„¤ì • (ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbd4dabf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'</s>'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ëª¨ë¸ì—ê²Œ ì£¼ì–´ì§ˆ í…ìŠ¤íŠ¸ì˜ í˜•ì‹ì„ ì •ì˜\n",
    "alpaca_prompt = \"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "{}\"\"\"\n",
    "\n",
    "# ë§¨ìœ—ì¤„: ëª¨ë¸ì—ê²Œ ì•ìœ¼ë¡œ ì œê³µë  ì§€ì‹œì‚¬í•­ì„ ê¸°ë°˜ìœ¼ë¡œ ì ì ˆí•œ ì‘ë‹µì„ ì‘ì„±í•˜ë¼ê³  ë§í•¨.\n",
    "# ëª¨ë¸ì´ ì–´ë–¤ ì‘ì—…ì„ ìˆ˜í–‰í•´ì•¼ í•˜ëŠ”ì§€ ëª…í™•íˆ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ë„ì™€ì¤Œ\n",
    "# Instruction:ì€ ì§€ì‹œì‚¬í•­ì´ ì œê³µë  ë¶€ë¶„\n",
    "# Response:ëŠ” ëª¨ë¸ì´ ìƒì„±í•´ì•¼ í•  ì‘ë‹µì´ ì œê³µë  ë¶€ë¶„\n",
    "\n",
    "# EOS í† í° ê°€ì ¸ì˜¤ê¸° (ìƒì„± ì¢…ë£Œë¥¼ ìœ„í•´ í•„ìš”)\n",
    "EOS_TOKEN = tokenizer.eos_token  # ë°˜ë“œì‹œ EOS_TOKENì„ ì¶”ê°€í•´ì•¼ í•¨\n",
    "EOS_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5a47ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 16412 examples [00:00, 48395.59 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16412/16412 [00:00<00:00, 73977.70 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# í”„ë¡¬í”„íŠ¸ í¬ë§·íŒ… í•¨ìˆ˜ ì •ì˜\n",
    "def formatting_prompts_func(examples):\n",
    "    instructions = examples[\"question\"]  # ë°ì´í„°ì…‹ì˜ 'instruction' í•„ë“œ\n",
    "    outputs      = examples[\"answer\"]       # ë°ì´í„°ì…‹ì˜ 'output' í•„ë“œ\n",
    "    texts = []\n",
    "    for instruction, output in zip(instructions, outputs):\n",
    "                                                           # EOS_TOKENì„ ì¶”ê°€í•˜ì§€ ì•Šìœ¼ë©´ ìƒì„±ì´ ë¬´í•œíˆ ê³„ì†ë¨\n",
    "        text = alpaca_prompt.format(instruction, output) + EOS_TOKEN  # í”„ë¡¬í”„íŠ¸ í˜•ì‹ì— ë§ê²Œ í…ìŠ¤íŠ¸ ìƒì„±\n",
    "        texts.append(text)\n",
    "    return { \"text\" : texts, }  # 'text' í•„ë“œë¡œ ë°˜í™˜\n",
    "\n",
    "# from datasets import load_dataset  # Hugging Face datasets ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "\n",
    "# ë°ì´í„°ì…‹ ë¡œë“œ (ê±´ì„¤ ì•ˆì „ RAFT ë°ì´í„°ì…‹)\n",
    "# dataset = load_dataset(\"YoungjaeDev/construction-safety-raft-kiwi-bm25-faiss-37\")\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í¬ë§·íŒ… í•¨ìˆ˜ ì ìš©í•˜ì—¬ ë°ì´í„°ì…‹ ë³€í™˜\n",
    "# dataset = dataset.map(formatting_prompts_func, batched = True,)\n",
    "\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset( \"csv\", data_files = \"/home/alpaco/chat_medquad/medquad.csv\", split = \"train\")\n",
    "dataset = dataset.map(formatting_prompts_func, batched=True)\n",
    "\n",
    "# ì˜ˆì œ ì—‘ì…€ í˜•íƒœë¡œ ë°ì´í„°ì…‹ì„ ë§Œë“ ë‹¤ë©´?\n",
    "# from datasets import load_dataset\n",
    "# dataset = load_dataset( \"csv\", data_files = \"data.csv\", split = \"train\")\n",
    "# dataset = dataset.map(formatting_prompts_func, batched=True)\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e683968c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nWhat is (are) Glaucoma ?\\n\\n### Response:\\nGlaucoma is a group of diseases that can damage the eye's optic nerve and result in vision loss and blindness. While glaucoma can strike anyone, the risk is much greater for people over 60. How Glaucoma Develops  There are several different types of glaucoma. Most of these involve the drainage system within the eye. At the front of the eye there is a small space called the anterior chamber. A clear fluid flows through this chamber and bathes and nourishes the nearby tissues. (Watch the video to learn more about glaucoma. To enlarge the video, click the brackets in the lower right-hand corner. To reduce the video, press the Escape (Esc) button on your keyboard.) In glaucoma, for still unknown reasons, the fluid drains too slowly out of the eye. As the fluid builds up, the pressure inside the eye rises. Unless this pressure is controlled, it may cause damage to the optic nerve and other parts of the eye and result in loss of vision. Open-angle Glaucoma The most common type of glaucoma is called open-angle glaucoma. In the normal eye, the clear fluid leaves the anterior chamber at the open angle where the cornea and iris meet. When fluid reaches the angle, it flows through a spongy meshwork, like a drain, and leaves the eye. Sometimes, when the fluid reaches the angle, it passes too slowly through the meshwork drain, causing the pressure inside the eye to build. If the pressure damages the optic nerve, open-angle glaucoma -- and vision loss -- may result. There is no cure for glaucoma. Vision lost from the disease cannot be restored. However, there are treatments that may save remaining vision. That is why early diagnosis is important.  See this graphic for a quick overview of glaucoma,  including how many people it affects, whos at risk, what to do if you have it, and how to learn more.  See a glossary of glaucoma terms.</s>\",\n",
       " 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nWhat causes Glaucoma ?\\n\\n### Response:\\nNearly 2.7 million people have glaucoma, a leading cause of blindness in the United States. Although anyone can get glaucoma, some people are at higher risk. They include - African-Americans over age 40  - everyone over age 60, especially Hispanics/Latinos  - people with a family history of glaucoma. African-Americans over age 40 everyone over age 60, especially Hispanics/Latinos people with a family history of glaucoma.  In addition to age, eye pressure is a risk factor. Whether you develop glaucoma depends on the level of pressure your optic nerve can tolerate without being damaged. This level is different for each person. Thats why a comprehensive dilated eye exam is very important. It can help your eye care professional determine what level of eye pressure is normal for you. Another risk factor for optic nerve damage relates to blood pressure. Thus, it is important to also make sure that your blood pressure is at a proper level for your body by working with your medical doctor. (Watch the animated video to learn more about the causes of glaucoma. To enlarge the video, click the brackets in the lower right-hand corner. To reduce the video, press the Escape (Esc) button on your keyboard.)</s>',\n",
       " 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nWhat are the symptoms of Glaucoma ?\\n\\n### Response:\\nSymptoms of Glaucoma  Glaucoma can develop in one or both eyes. The most common type of glaucoma, open-angle glaucoma, has no symptoms at first. It causes no pain, and vision seems normal. Without treatment, people with glaucoma will slowly lose their peripheral, or side vision. They seem to be looking through a tunnel. Over time, straight-ahead vision may decrease until no vision remains. Tests for Glaucoma Glaucoma is detected through a comprehensive eye exam that includes a visual acuity test, visual field test, dilated eye exam, tonometry, and pachymetry. (Watch the animated video to learn more about testing for glaucoma. To enlarge the video, click the brackets in the lower right-hand corner. To reduce the video, press the Escape (Esc) button on your keyboard.)  A visual acuity test uses an eye chart test to measure how well you see at various distances. A visual field test measures your side or peripheral vision. It helps your eye care professional tell if you have lost side vision, a sign of glaucoma. In a dilated eye exam, drops are placed in your eyes to widen, or dilate, the pupils. Your eye care professional uses a special magnifying lens to examine your retina and optic nerve for signs of damage and other eye problems. After the exam, your close-up vision may remain blurred for several hours. In tonometry, an instrument measures the pressure inside the eye. Numbing drops may be applied to your eye for this test. With pachymetry,  a numbing drop is applied to your eye. Your eye care professional uses an ultrasonic wave instrument to measure the thickness of your cornea.</s>',\n",
       " 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nWhat are the treatments for Glaucoma ?\\n\\n### Response:\\nAlthough open-angle glaucoma cannot be cured, it can usually be controlled. While treatments may save remaining vision, they do not improve sight already lost from glaucoma. The most common treatments for glaucoma are medication and surgery. Medications  Medications for glaucoma may be either in the form of eye drops or pills. Some drugs reduce pressure by slowing the flow of fluid into the eye. Others help to improve fluid drainage. (Watch the video to learn more about coping with glaucoma. To enlarge the video, click the brackets in the lower right-hand corner. To reduce the video, press the Escape (Esc) button on your keyboard.) For most people with glaucoma, regular use of medications will control the increased fluid pressure. But, these drugs may stop working over time. Or, they may cause side effects. If a problem occurs, the eye care professional may select other drugs, change the dose, or suggest other ways to deal with the problem.  Read or listen to ways some patients are coping with glaucoma. Surgery Laser surgery is another treatment for glaucoma. During laser surgery, a strong beam of light is focused on the part of the anterior chamber where the fluid leaves the eye. This results in a series of small changes that makes it easier for fluid to exit the eye. Over time, the effect of laser surgery may wear off. Patients who have this form of surgery may need to keep taking glaucoma drugs. Researching Causes and Treatments Through studies in the laboratory and with patients, NEI is seeking better ways to detect, treat, and prevent vision loss in people with glaucoma. For example, researchers have discovered genes that could help explain how glaucoma damages the eye. NEI also is supporting studies to learn more about who is likely to get glaucoma, when to treat people who have increased eye pressure, and which treatment to use first.</s>',\n",
       " \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nWhat is (are) Glaucoma ?\\n\\n### Response:\\nGlaucoma is a group of diseases that can damage the eye's optic nerve and result in vision loss and blindness. The most common form of the disease is open-angle glaucoma. With early treatment, you can often protect your eyes against serious vision loss. (Watch the video to learn more about glaucoma. To enlarge the video, click the brackets in the lower right-hand corner. To reduce the video, press the Escape (Esc) button on your keyboard.)  See this graphic for a quick overview of glaucoma, including how many people it affects, whos at risk, what to do if you have it, and how to learn more.  See a glossary of glaucoma terms.</s>\"]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['text'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2eafcbee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Tokenizing [\"text\"] (num_proc=2): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16412/16412 [00:08<00:00, 1853.53 examples/s]\n",
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 16,412 | Num Epochs = 1 | Total steps = 60\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
      " \"-____-\"     Trainable parameters = 41,943,040/7,000,000,000 (0.60% trained)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [60/60 03:55, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.301800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.451600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.559300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.292200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.362500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.275900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.186000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.180300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.097500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.021700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.956600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.009700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.869100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.904400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.681000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.042600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.742900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.752500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.904700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.626900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.743200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1.104200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.845600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.844400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.920200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.715700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>1.067400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.671600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.843200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.984700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.890900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.845200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.576400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.809500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.864000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.676600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.962300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.477300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.825500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.944700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>1.006500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.710300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.692400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.820700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.669500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.839700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.693700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.772600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.859000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.905400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.892700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>1.006100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.577700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.472200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>1.024900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.866200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.720600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.674900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.841000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.889600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## í•™ìŠµ ì„¤ì •\n",
    "from trl import SFTTrainer  # TRL ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ SFTTrainer ì„í¬íŠ¸\n",
    "from transformers import TrainingArguments  # íŠ¸ëœìŠ¤í¬ë¨¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ TrainingArguments ì„í¬íŠ¸\n",
    "from unsloth import is_bfloat16_supported  # BFloat16 ì§€ì› ì—¬ë¶€ í™•ì¸ í•¨ìˆ˜ ì„í¬íŠ¸\n",
    "\n",
    "# SFTTrainer ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "trainer = SFTTrainer(\n",
    "    model = model,                           # í•™ìŠµí•  ëª¨ë¸\n",
    "    tokenizer = tokenizer,                   # ì‚¬ìš©í•  í† í¬ë‚˜ì´ì €\n",
    "    train_dataset = dataset,                 # í•™ìŠµí•  ë°ì´í„°ì…‹ â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…\n",
    "    dataset_text_field = \"text\",             # ë°ì´í„°ì…‹ì˜ í…ìŠ¤íŠ¸ í•„ë“œ ì´ë¦„ â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…\n",
    "    max_seq_length = max_seq_length,         # ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´\n",
    "    dataset_num_proc = 2,                    # ë°ì´í„°ì…‹ ì „ì²˜ë¦¬ì— ì‚¬ìš©í•  í”„ë¡œì„¸ìŠ¤ ìˆ˜ cpu\n",
    "    packing = False,                         # ì§§ì€ ì‹œí€€ìŠ¤ì˜ ê²½ìš° packingì„ ë¹„í™œì„±í™” (í•™ìŠµ ì†ë„ 5ë°° í–¥ìƒ ê°€ëŠ¥)\n",
    "    args = TrainingArguments(\n",
    "        per_device_train_batch_size = 2,     # ë””ë°”ì´ìŠ¤ ë‹¹ ë°°ì¹˜ ì‚¬ì´ì¦ˆ\n",
    "        gradient_accumulation_steps = 4,     # ê·¸ë˜ë””ì–¸íŠ¸ ëˆ„ì  ë‹¨ê³„ ìˆ˜\n",
    "        warmup_steps = 5,                     # ì›Œë°ì—… ìŠ¤í… ìˆ˜\n",
    "        # num_train_epochs = 1,               # ì „ì²´ í•™ìŠµ ì—í­ ìˆ˜ ì„¤ì • ê°€ëŠ¥\n",
    "        max_steps = 60,                       # ìµœëŒ€ í•™ìŠµ ìŠ¤í… ìˆ˜\n",
    "        learning_rate = 2e-4,                 # í•™ìŠµë¥ \n",
    "        fp16 = not is_bfloat16_supported(),   # BFloat16 ì§€ì› ì—¬ë¶€ì— ë”°ë¼ FP16 ì‚¬ìš©\n",
    "        bf16 = is_bfloat16_supported(),       # BFloat16 ì‚¬ìš© ì—¬ë¶€\n",
    "        logging_steps = 1,                    # ë¡œê¹… ë¹ˆë„\n",
    "        optim = \"adamw_8bit\",                  # ì˜µí‹°ë§ˆì´ì € ì„¤ì • (8ë¹„íŠ¸ AdamW)\n",
    "        weight_decay = 0.01,                  # ê°€ì¤‘ì¹˜ ê°ì‡ \n",
    "        lr_scheduler_type = \"linear\",         # í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ íƒ€ì…\n",
    "        seed = 3407,                           # ëœë¤ ì‹œë“œ ì„¤ì •\n",
    "        output_dir = \"outputs\",                # ì¶œë ¥ ë””ë ‰í† ë¦¬\n",
    "    ),\n",
    ")\n",
    "\n",
    "## í•™ìŠµ ì‹¤í–‰\n",
    "trainer_stats = trainer.train()  # ëª¨ë¸ í•™ìŠµ ì‹œì‘ # 3d6e4b9a0ddcd9edfafad59dcde0fd8c666954fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "289487f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('medquad/tokenizer_config.json',\n",
       " 'medquad/special_tokens_map.json',\n",
       " 'medquad/tokenizer.model',\n",
       " 'medquad/added_tokens.json',\n",
       " 'medquad/tokenizer.json')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ëª¨ë¸ ì €ì¥ ë¡œì»¬í´ë”ì—ë‹¤ê°€ ì €ì¥í•˜ëŠ” ë°©ì‹\n",
    "model.save_pretrained(\"medquad\")  # Local saving\n",
    "tokenizer.save_pretrained(\"medquad\")  # í† í¬ë‚˜ì´ì €ë„ í•¨ê»˜ ì €ì¥\n",
    "\n",
    "# ì´ ì´ì™¸ì— í—ˆê¹…í˜ì´ìŠ¤ë‚˜ ë‹¤ë¥¸ hubì— pushí•´ì„œ ì €ì¥í•˜ëŠ” ë°©ë²•ì´ ìˆìŒ\n",
    "# ë‹¤ë§Œ, ì—…ë¡œë“œ ì†ë„ì™€ ë‹¤ìš´ë¡œë“œ ì†ë„ë¥¼ ê³ ë ¤í•´ì•¼í•¨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9490af10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.5.7: Fast Mistral patching. Transformers: 4.51.3.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 3090. Num GPUs = 1. Max memory: 23.691 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.4.0+cu121. CUDA: 8.6. CUDA Toolkit: 12.1. Triton: 3.0.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.27.post2+cu118. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Will load /home/alpaco/chat_medquad/medquad as a legacy tokenizer.\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "\n",
    "# ì €ì¥ëœ ê²½ë¡œ ì§€ì •\n",
    "save_directory = \"/home/alpaco/chat_medquad/medquad\"  # ëª¨ë¸ì´ ì €ì¥ëœ ë””ë ‰í† ë¦¬ ê²½ë¡œ\n",
    "\n",
    "# ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = save_directory,\n",
    "    max_seq_length = 2048,\n",
    "    dtype = None,\n",
    "    load_in_4bit = True,  # ì–‘ìí™” ì˜µì…˜ì„ ë™ì¼í•˜ê²Œ ì„¤ì •\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28578e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is (are) Glaucoma ?\n",
      "\n",
      "### Response:\n",
      "Glaucoma is a group of eye conditions that damage the optic nerve, which is responsible for relaying visual information from the eye to the brain. The most common type of glaucoma is primary open-angle glaucoma, which is often associated with aging. Other types of glaucoma include angle-closure glaucoma, congenital glaucoma, secondary glaucoma, and normal-tension glaucoma. Glaucoma is often associated with increased pressure within the eye, although this is not always the case. The increased pressure damages the optic nerve\n"
     ]
    }
   ],
   "source": [
    "# ì¶”ë¡ í•´ë³´ê¸°\n",
    "FastLanguageModel.for_inference(model)  # ë„¤ì´í‹°ë¸Œ 2ë°° ë¹ ë¥¸ ì¶”ë¡  í™œì„±í™”\n",
    "\n",
    "# ì¶”ë¡ ì„ ìœ„í•œ ì…ë ¥ ì¤€ë¹„\n",
    "inputs = tokenizer(\n",
    "[\n",
    "    alpaca_prompt.format(\n",
    "        \"What is (are) Glaucoma ?\", # ì¸ìŠ¤íŠ¸ëŸ­ì…˜ (ëª…ë ¹ì–´)\n",
    "        \"\", # ì¶œë ¥ - ìƒì„±í•  ë‹µë³€ì„ ë¹„ì›Œë‘ \n",
    "    )\n",
    "], return_tensors = \"pt\").to(\"cuda\")  # í…ì„œë¥¼ PyTorch í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ê³  GPUë¡œ ì´ë™\n",
    "\n",
    "from transformers import TextStreamer  # í…ìŠ¤íŠ¸ ìŠ¤íŠ¸ë¦¬ë°ì„ ìœ„í•œ TextStreamer ì„í¬íŠ¸\n",
    "\n",
    "text_streamer = TextStreamer(tokenizer)  # í† í¬ë‚˜ì´ì €ë¥¼ ì‚¬ìš©í•˜ì—¬ ìŠ¤íŠ¸ë¦¬ë¨¸ ì´ˆê¸°í™”\n",
    "\n",
    "# ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ìƒì„± ë° ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥\n",
    "_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128)  # ìµœëŒ€ 128ê°œì˜ ìƒˆë¡œìš´ í† í° ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36e20461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Glaucoma is a group of eye conditions that damage the optic nerve, which is responsible for relaying visual information from the eye to the brain. The most common type of glaucoma is primary open-angle glaucoma, which is often associated with aging. Other types of glaucoma include angle-closure glaucoma, congenital glaucoma, secondary glaucoma, and normal-tension glaucoma. Glaucoma is often associated with increased pressure within the eye, although this is not always the case. The increased pressure damages the optic nerve'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ë‹µë³€ë§Œ ì¶”ì¶œ\n",
    "generated_text = tokenizer.decode(_[0], skip_special_tokens=True)\n",
    "generated_text.split(\"### Response:\")[1].strip()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fast_chat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
